{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10623654,"sourceType":"datasetVersion","datasetId":6577794},{"sourceId":247475,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":211504,"modelId":233199},{"sourceId":248124,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":212061,"modelId":233737},{"sourceId":248336,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":212249,"modelId":233923},{"sourceId":259187,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":221562,"modelId":243340}],"dockerImageVersionId":30841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:19.807518Z","iopub.execute_input":"2025-02-15T15:58:19.807946Z","iopub.status.idle":"2025-02-15T15:58:19.818134Z","shell.execute_reply.started":"2025-02-15T15:58:19.807921Z","shell.execute_reply":"2025-02-15T15:58:19.817431Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gru_96/keras/default/1/model_96.h5\n/kaggle/input/amazon-dataset/data.npz\n/kaggle/input/emb/keras/default/1/fully_pruned_model_latest.h5\n/kaggle/input/gru_90/keras/default/1/model_90.h5\n/kaggle/input/gru_pruned_model/keras/default/1/model_60.h5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T13:25:10.275477Z","iopub.execute_input":"2025-02-15T13:25:10.275818Z","iopub.status.idle":"2025-02-15T13:25:21.965764Z","shell.execute_reply.started":"2025-02-15T13:25:10.275789Z","shell.execute_reply":"2025-02-15T13:25:21.965045Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load the pruned model\npruned_model = tf.keras.models.load_model(\"/kaggle/input/emb/keras/default/1/fully_pruned_model_latest.h5\")\npruned_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T13:25:21.966829Z","iopub.execute_input":"2025-02-15T13:25:21.967397Z","iopub.status.idle":"2025-02-15T13:25:24.708319Z","shell.execute_reply.started":"2025-02-15T13:25:21.967363Z","shell.execute_reply":"2025-02-15T13:25:24.707549Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m1,920,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m49,920\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m74,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,069,251\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,251</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,069,249\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,249</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\ndef count_trainable_zero_nonzero_params(model):\n    total_params = 0\n    zero_params = 0\n    nonzero_params = 0\n\n    # Iterate over trainable variables of the model\n    for var in model.trainable_variables:\n        total = tf.size(var).numpy()  # Total number of parameters in the variable\n        zero = np.sum(var.numpy() == 0)  # Count zero parameters\n        nonzero = total - zero  # Non-zero parameters\n\n        total_params += total\n        zero_params += zero\n        nonzero_params += nonzero\n\n    return total_params, zero_params, nonzero_params\n\n# Example Usage\ntotal, zero, nonzero = count_trainable_zero_nonzero_params(pruned_model)\nprint(f\"Total Trainable Parameters: {total}\")\nprint(f\"Zero Trainable Parameters: {zero}\")\nprint(f\"Non-Zero Trainable Parameters: {nonzero}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T13:25:27.506903Z","iopub.execute_input":"2025-02-15T13:25:27.507262Z","iopub.status.idle":"2025-02-15T13:25:27.556773Z","shell.execute_reply.started":"2025-02-15T13:25:27.507236Z","shell.execute_reply":"2025-02-15T13:25:27.555750Z"}},"outputs":[{"name":"stdout","text":"Total Trainable Parameters: 2069249\nZero Trainable Parameters: 146608\nNon-Zero Trainable Parameters: 1922641\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def layerwise_trainable_zero_nonzero_params(model):\n    for layer in model.layers:\n        if hasattr(layer, 'trainable_variables'):\n            for var in layer.trainable_variables:\n                total = tf.size(var).numpy()\n                zero = np.sum(var.numpy() == 0)\n                nonzero = total - zero\n                print(f\"Layer: {layer.name} | Total: {total} | Zero: {zero} | Non-Zero: {nonzero}\")\n\n# Example Usage\nlayerwise_trainable_zero_nonzero_params(pruned_model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T13:25:38.335287Z","iopub.execute_input":"2025-02-15T13:25:38.335570Z","iopub.status.idle":"2025-02-15T13:25:38.370909Z","shell.execute_reply.started":"2025-02-15T13:25:38.335550Z","shell.execute_reply":"2025-02-15T13:25:38.370033Z"}},"outputs":[{"name":"stdout","text":"Layer: embedding | Total: 1920000 | Zero: 3392 | Non-Zero: 1916608\nLayer: bidirectional | Total: 12288 | Zero: 11505 | Non-Zero: 783\nLayer: bidirectional | Total: 12288 | Zero: 11488 | Non-Zero: 800\nLayer: bidirectional | Total: 384 | Zero: 370 | Non-Zero: 14\nLayer: bidirectional | Total: 12288 | Zero: 11346 | Non-Zero: 942\nLayer: bidirectional | Total: 12288 | Zero: 11489 | Non-Zero: 799\nLayer: bidirectional | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: bidirectional_1 | Total: 24576 | Zero: 24058 | Non-Zero: 518\nLayer: bidirectional_1 | Total: 12288 | Zero: 11971 | Non-Zero: 317\nLayer: bidirectional_1 | Total: 384 | Zero: 379 | Non-Zero: 5\nLayer: bidirectional_1 | Total: 24576 | Zero: 23691 | Non-Zero: 885\nLayer: bidirectional_1 | Total: 12288 | Zero: 11709 | Non-Zero: 579\nLayer: bidirectional_1 | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: dense | Total: 16384 | Zero: 16288 | Non-Zero: 96\nLayer: dense | Total: 128 | Zero: 127 | Non-Zero: 1\nLayer: dense_1 | Total: 8192 | Zero: 8023 | Non-Zero: 169\nLayer: dense_1 | Total: 64 | Zero: 56 | Non-Zero: 8\nLayer: dense_2 | Total: 64 | Zero: 0 | Non-Zero: 64\nLayer: dense_2 | Total: 1 | Zero: 0 | Non-Zero: 1\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# import tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_bigru_dense_zero_mask(model):\n    \"\"\"\n    Creates a mask for BiGRU and Dense layers where weights are zero.\n    \"\"\"\n    masks = []\n    for layer in model.layers:\n        if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Bidirectional)):\n            layer_masks = []\n            for weight in layer.trainable_weights:\n                mask = tf.cast(weight != 0, tf.float32)  # Mask: 1 for non-zero, 0 for zero\n                layer_masks.append(mask)\n            masks.append(layer_masks)\n    return masks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:25.803123Z","iopub.execute_input":"2025-02-15T15:58:25.803434Z","iopub.status.idle":"2025-02-15T15:58:25.808333Z","shell.execute_reply.started":"2025-02-15T15:58:25.803383Z","shell.execute_reply":"2025-02-15T15:58:25.807383Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def prune_embedding_lth(model, prune_ratio):\n    \"\"\"\n    Prunes the Embedding layer using the Lottery Ticket Hypothesis.\n    \"\"\"\n    embedding_layer = None\n    for layer in model.layers:\n        if isinstance(layer, tf.keras.layers.Embedding):\n            embedding_layer = layer\n            break\n\n    if embedding_layer is None:\n        raise ValueError(\"No embedding layer found in the model.\")\n\n    # Get current embedding weights\n    embedding_weights = embedding_layer.get_weights()[0]\n    \n    # Compute global threshold\n    flat_weights = np.abs(embedding_weights.flatten())\n    threshold = np.percentile(flat_weights, prune_ratio)\n\n    # Create mask\n    mask = tf.cast(tf.abs(embedding_weights) >= threshold, tf.float32)\n\n    # Apply mask to embedding weights\n    pruned_weights = embedding_weights * mask\n    embedding_layer.set_weights([pruned_weights])\n\n    return model, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:28.534745Z","iopub.execute_input":"2025-02-15T15:58:28.535156Z","iopub.status.idle":"2025-02-15T15:58:28.541896Z","shell.execute_reply.started":"2025-02-15T15:58:28.535120Z","shell.execute_reply":"2025-02-15T15:58:28.540985Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def apply_bigru_dense_mask(model, masks):\n    \"\"\"\n    Re-applies the zero mask to BiGRU and Dense layers after training updates.\n    \"\"\"\n    idx = 0\n    for layer in model.layers:\n        if isinstance(layer, (tf.keras.layers.Dense, tf.keras.layers.Bidirectional)):\n            for i, weight in enumerate(layer.trainable_weights):\n                weight.assign(weight * masks[idx][i])  # Apply mask to retain zero weights\n            idx += 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:31.383835Z","iopub.execute_input":"2025-02-15T15:58:31.384244Z","iopub.status.idle":"2025-02-15T15:58:31.389566Z","shell.execute_reply.started":"2025-02-15T15:58:31.384209Z","shell.execute_reply":"2025-02-15T15:58:31.388677Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def rewind_embedding_preserving_zeros(model, initial_embedding_weights, embedding_mask):\n    \"\"\"\n    Rewinds the embedding layer to its initial values while preserving zeroed-out weights.\n    \"\"\"\n    for layer in model.layers:\n        if isinstance(layer, tf.keras.layers.Embedding):\n            restored_weights = initial_embedding_weights * embedding_mask  # Apply mask\n            layer.set_weights([restored_weights])\n            break  # Since there's only one embedding layer, exit loop\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:31.605386Z","iopub.execute_input":"2025-02-15T15:58:31.605727Z","iopub.status.idle":"2025-02-15T15:58:31.610027Z","shell.execute_reply.started":"2025-02-15T15:58:31.605702Z","shell.execute_reply":"2025-02-15T15:58:31.608991Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:34.369889Z","iopub.execute_input":"2025-02-15T15:58:34.370166Z","iopub.status.idle":"2025-02-15T15:58:45.840182Z","shell.execute_reply.started":"2025-02-15T15:58:34.370146Z","shell.execute_reply":"2025-02-15T15:58:45.839523Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"/kaggle/input/gru_96/keras/default/1/model_96.h5\")\n# 1️⃣ Create mask for BiGRU and Dense layers (zero weights)\nbigru_dense_masks = create_bigru_dense_zero_mask(model)\n\n# 2️⃣ Prune Embedding layer using LTH\nprune_ratio = 96  # Adjust pruning percentage\nmodel, embedding_mask = prune_embedding_lth(model, prune_ratio=prune_ratio)\n\n# Save original embedding weights before pruning\nfor layer in model.layers:\n    if isinstance(layer, tf.keras.layers.Embedding):\n        initial_embedding_weights = layer.get_weights()[0]\n        break\n\n# 3️⃣ Rewind Embedding while keeping zero weights unchanged\nmodel = rewind_embedding_preserving_zeros(model, initial_embedding_weights, embedding_mask)\n\ndata = np.load(\"/kaggle/input/amazon-dataset/data.npz\")\n\ndef get_accuracy(model, val_dataset):\n    # Initialize accuracy metric\n    accuracy = tf.keras.metrics.BinaryAccuracy()\n    # Iterate over validation dataset\n    for x, y in val_dataset:\n        # Predict and update accuracy state\n        y_pred = model(x)\n        accuracy.update_state(y, y_pred)\n    # Return final accuracy result\n    return accuracy.result().numpy()\n\n# Convert to tensors\nX_train = tf.convert_to_tensor(data[\"X_train\"], dtype=tf.float32)\ny_train = tf.convert_to_tensor(data[\"y_train\"], dtype=tf.float32)\nX_val = tf.convert_to_tensor(data[\"X_val\"], dtype=tf.float32)\ny_val = tf.convert_to_tensor(data[\"y_val\"], dtype=tf.float32)\n\n# Smaller validation subset\nval_sample_size = 8000\nX_val = X_val[:val_sample_size]\ny_val = y_val[:val_sample_size]\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_ds = train_ds.shuffle(10000).batch(1900)\n\nlearning_rate = 0.001\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nloss_fn = tf.keras.losses.BinaryCrossentropy()\n\n# 4️⃣ Train while applying BiGRU & Dense zero masks\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    for x_batch, y_batch in train_ds:\n        with tf.GradientTape() as tape:\n            y_pred = model(x_batch, training=True)\n            loss = loss_fn(y_batch, y_pred)\n\n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        # Reapply BiGRU & Dense masks after each update\n        apply_bigru_dense_mask(model, bigru_dense_masks)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n\n# Evaluate performance\nval_accuracy = get_accuracy(model, val_dataset)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n# Save the final pruned model\nmodel.save(\"/kaggle/working/fully_pruned_model00.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T15:58:45.841273Z","iopub.execute_input":"2025-02-15T15:58:45.841908Z","iopub.status.idle":"2025-02-15T16:57:51.000042Z","shell.execute_reply.started":"2025-02-15T15:58:45.841884Z","shell.execute_reply":"2025-02-15T16:57:50.999036Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3 completed.\nEpoch 2/3 completed.\nEpoch 3/3 completed.\nValidation Accuracy: 0.9308\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T16:57:51.001449Z","iopub.execute_input":"2025-02-15T16:57:51.001756Z","iopub.status.idle":"2025-02-15T16:57:51.023632Z","shell.execute_reply.started":"2025-02-15T16:57:51.001732Z","shell.execute_reply":"2025-02-15T16:57:51.022923Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m1,920,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m49,920\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m74,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,069,251\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,251</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,069,249\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,249</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\ndef count_trainable_zero_nonzero_params(model):\n    total_params = 0\n    zero_params = 0\n    nonzero_params = 0\n\n    # Iterate over trainable variables of the model\n    for var in model.trainable_variables:\n        total = tf.size(var).numpy()  # Total number of parameters in the variable\n        zero = np.sum(var.numpy() == 0)  # Count zero parameters\n        nonzero = total - zero  # Non-zero parameters\n\n        total_params += total\n        zero_params += zero\n        nonzero_params += nonzero\n\n    return total_params, zero_params, nonzero_params\n\n# Example Usage\ntotal, zero, nonzero = count_trainable_zero_nonzero_params(model)\nprint(f\"Total Trainable Parameters: {total}\")\nprint(f\"Zero Trainable Parameters: {zero}\")\nprint(f\"Non-Zero Trainable Parameters: {nonzero}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T16:57:51.024625Z","iopub.execute_input":"2025-02-15T16:57:51.024907Z","iopub.status.idle":"2025-02-15T16:57:51.055489Z","shell.execute_reply.started":"2025-02-15T16:57:51.024875Z","shell.execute_reply":"2025-02-15T16:57:51.054714Z"}},"outputs":[{"name":"stdout","text":"Total Trainable Parameters: 2069249\nZero Trainable Parameters: 146608\nNon-Zero Trainable Parameters: 1922641\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def layerwise_trainable_zero_nonzero_params(model):\n    for layer in model.layers:\n        if hasattr(layer, 'trainable_variables'):\n            for var in layer.trainable_variables:\n                total = tf.size(var).numpy()\n                zero = np.sum(var.numpy() == 0)\n                nonzero = total - zero\n                print(f\"Layer: {layer.name} | Total: {total} | Zero: {zero} | Non-Zero: {nonzero}\")\n\n# Example Usage\nlayerwise_trainable_zero_nonzero_params(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T16:57:51.056315Z","iopub.execute_input":"2025-02-15T16:57:51.056685Z","iopub.status.idle":"2025-02-15T16:57:51.084574Z","shell.execute_reply.started":"2025-02-15T16:57:51.056650Z","shell.execute_reply":"2025-02-15T16:57:51.083855Z"}},"outputs":[{"name":"stdout","text":"Layer: embedding | Total: 1920000 | Zero: 3392 | Non-Zero: 1916608\nLayer: bidirectional | Total: 12288 | Zero: 11505 | Non-Zero: 783\nLayer: bidirectional | Total: 12288 | Zero: 11488 | Non-Zero: 800\nLayer: bidirectional | Total: 384 | Zero: 370 | Non-Zero: 14\nLayer: bidirectional | Total: 12288 | Zero: 11346 | Non-Zero: 942\nLayer: bidirectional | Total: 12288 | Zero: 11489 | Non-Zero: 799\nLayer: bidirectional | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: bidirectional_1 | Total: 24576 | Zero: 24058 | Non-Zero: 518\nLayer: bidirectional_1 | Total: 12288 | Zero: 11971 | Non-Zero: 317\nLayer: bidirectional_1 | Total: 384 | Zero: 379 | Non-Zero: 5\nLayer: bidirectional_1 | Total: 24576 | Zero: 23691 | Non-Zero: 885\nLayer: bidirectional_1 | Total: 12288 | Zero: 11709 | Non-Zero: 579\nLayer: bidirectional_1 | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: dense | Total: 16384 | Zero: 16288 | Non-Zero: 96\nLayer: dense | Total: 128 | Zero: 127 | Non-Zero: 1\nLayer: dense_1 | Total: 8192 | Zero: 8023 | Non-Zero: 169\nLayer: dense_1 | Total: 64 | Zero: 56 | Non-Zero: 8\nLayer: dense_2 | Total: 64 | Zero: 0 | Non-Zero: 64\nLayer: dense_2 | Total: 1 | Zero: 0 | Non-Zero: 1\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}